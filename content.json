{"meta":{"title":"Kind Net","subtitle":null,"description":null,"author":"Shanyi Wang","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-07-02T00:43:04.000Z","updated":"2018-07-02T00:43:04.265Z","comments":true,"path":"about/index-1.html","permalink":"http://yoursite.com/about/index-1.html","excerpt":"","text":""},{"title":"about","date":"2018-07-02T00:40:15.000Z","updated":"2018-07-02T00:40:15.373Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"神经网络-卷积神经网络","slug":"deeplearning-cnn","date":"2018-07-14T12:28:19.000Z","updated":"2018-07-14T13:45:17.530Z","comments":true,"path":"2018/07/14/deeplearning-cnn/","link":"","permalink":"http://yoursite.com/2018/07/14/deeplearning-cnn/","excerpt":"","text":"卷积神经网络·卷积神经网络（Convolutional Neural Network, CNN）是神经网络的一种。它的架构一般包括卷积层，池化层，全连接层组成。卷积神经网络一般用在图像处理中。 卷积卷积可以看做是特征提取，作为一个滤波器。我们可以定义多个卷积。我们使用了n个卷积，即得到n组不同的特征，n个通道(channel)。卷积的方式在指定f * f 卷积核内，对应点相乘的累加和。例如我们的卷积核为 \\begin{matrix} 1 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ \\end{matrix}如果原图有一个符合X形状的特征块，那么卷积值很高，否则很低。 池化池化是对卷积层的特征做一个下采样，得到更小的特征。池化的常用的有：1) Max pooling 2) Average pooling。 我们实际上常用为MaxPolling。 图像大小填充数量方式：Valid: no PaddingSame: 卷积后和输入同样的大小。 原图像大小是n_wn_h, 过滤器是ff, Padding 是P，步长s，最后输出的图像大小是 [(n_w+2p-f)/s+1]*[(n_h+2p-f)/s+1]优缺点优点：1） 共享卷积核 2）不需要手动选取特征缺点：1) 神经网络的特征过多 2）物理含义不明确，不知道卷积提取的特征是什么","categories":[],"tags":[{"name":"DeepLearning, CNN","slug":"DeepLearning-CNN","permalink":"http://yoursite.com/tags/DeepLearning-CNN/"}]},{"title":"深度学习-感知机","slug":"deeplearning-perception","date":"2018-07-08T08:28:42.000Z","updated":"2018-07-08T08:32:49.059Z","comments":true,"path":"2018/07/08/deeplearning-perception/","link":"","permalink":"http://yoursite.com/2018/07/08/deeplearning-perception/","excerpt":"","text":"感知机感知机(Perceptron)算法是一种很好的二分类在线算法，它要求是线性可分的模型，感知机对应于在输入的空间中将实例划分成正负样本，分离它们的是分离超平面，即判别的模型。感知机被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。 函数定义z = w_1*x_1 + w_2+x_2 {\\cdots} w_n*x_na = sigmod(z)损失函数(Loss Function)和代价函数(Cost Function)首先明确下损失函数概念和代价函数，感知机是通过损失函数计算偏差。损失函数：Loss(error) function 对于单个样本预计值与真实值的偏差 L(a,y) = -(yloga + (1-y)log(1-a))代价函数：Cost function 对于所有样本loss的平均值 J(w,b) = \\frac{1}{m} * \\sum_{i=1}^m -(yloga + (1-y)log(1-a))逻辑回归公式推导 逻辑回归公式向量化 代码1234567def propagate(w, b, X, Y): m = X.shape[1] A = sigmoid(np.dot(w.T, X) + b) cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))) dw = (1 / m) * np.dot(X, (A - Y).T) db = (1 / m) * np.sum(A - Y) cost = np.squeeze(cost)","categories":[],"tags":[{"name":"DeepLearning, Perception","slug":"DeepLearning-Perception","permalink":"http://yoursite.com/tags/DeepLearning-Perception/"}]}]}